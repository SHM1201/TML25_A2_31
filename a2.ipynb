{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0594a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: onnx in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (1.18.0)\n",
      "Requirement already satisfied: onnxruntime in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (1.22.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: datasets in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from onnx) (2.3.0)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from onnx) (6.31.1)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from onnx) (4.14.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\hassa\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from transformers) (0.32.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.12)\n",
      "Requirement already satisfied: psutil in c:\\users\\hassa\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from matplotlib) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hassa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hassa\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hassa\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from pandas->datasets) (2025.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests onnx onnxruntime transformers datasets accelerate sentencepiece matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50de6c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: torch==2.7.1 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torchvision) (2.7.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch==2.7.1->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch==2.7.1->torchvision) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch==2.7.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch==2.7.1->torchvision) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch==2.7.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch==2.7.1->torchvision) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from torch==2.7.1->torchvision) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hassa\\anaconda3\\envs\\tml_a2\\lib\\site-packages (from jinja2->torch==2.7.1->torchvision) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa83919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import sys\n",
    "import base64\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf14ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 36604352, 'port': '9340'}\n"
     ]
    }
   ],
   "source": [
    "### REQUESTING NEW API ### \n",
    "TOKEN = \"61729223\" \n",
    " \n",
    "response = requests.get(\"http://34.122.51.94:9090\" + \"/stealing_launch\", \n",
    "headers={\"token\": TOKEN}) \n",
    "answer = response.json() \n",
    " \n",
    "print(answer) \n",
    "if 'detail' in answer: \n",
    "    sys.exit(1) \n",
    " \n",
    "# save the values \n",
    "SEED = str(answer['seed']) \n",
    "PORT = str(answer['port']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f74078",
   "metadata": {},
   "source": [
    "{'seed': 36604352, 'port': '9340'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad5f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if not self.transform is None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e09f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.2980, 0.2962, 0.2987]\n",
    "std = [0.2886, 0.2875, 0.2889]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "dataset: TaskDataset = torch.load(\"ModelStealingPub.pt\", weights_only=False)\n",
    "dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b17d5f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from typing import List, Dict\n",
    "\n",
    "def model_stealing(ids: List[int], imgs: List, port: int) -> List[Dict]:\n",
    "    endpoint = \"/query\"\n",
    "    url = f\"http://34.122.51.94:{port}{endpoint}\"\n",
    "    \n",
    "    image_data = []\n",
    "    for img in imgs:\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        image_data.append(img_base64)\n",
    "\n",
    "    payload = json.dumps(image_data)\n",
    "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": TOKEN})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        representations = response.json()[\"representations\"]\n",
    "        output = [\n",
    "            {\"id\": id_, \"img\": img, \"label\": rep}\n",
    "            for id_, img, rep in zip(ids, imgs, representations)\n",
    "        ]\n",
    "        return output\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Model stealing failed. Code: {response.status_code}, content: {response.json()}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825a476",
   "metadata": {},
   "source": [
    "Querying data from the vitcim model in batch of 1000s with time delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "700f1c3c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 2 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 3 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 4 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 5 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 6 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 7 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 8 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 9 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 10 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 11 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 12 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 13 processed successfully.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 1000\n",
    "all_records = []\n",
    "\n",
    "# Shuffle and batch\n",
    "indices = np.random.permutation(len(dataset))\n",
    "\n",
    "for start in range(0, len(indices), batch_size):\n",
    "    end = start + batch_size\n",
    "    batch_indices = indices[start:end]\n",
    "\n",
    "    batch_ids = [dataset.ids[i] for i in batch_indices]\n",
    "    batch_imgs = [dataset.imgs[i] for i in batch_indices]\n",
    "\n",
    "    try:\n",
    "        batch_output = model_stealing(batch_ids, batch_imgs, port=PORT)\n",
    "        all_records.extend(batch_output)\n",
    "        print(f\"Batch {start // batch_size + 1} processed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error on batch {start // batch_size + 1}: {e}\")\n",
    "    \n",
    "    # Wait 90 seconds (1.5 minutes) between requests\n",
    "    if end < len(indices):  # Avoid waiting after last batch\n",
    "        print(\"Waiting 90 seconds to respect API rate limit...\")\n",
    "        time.sleep(90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0561a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\nTotal records collected: {len(all_records)}\\n\")\n",
    "\n",
    "# Print few samples\n",
    "for i, record in enumerate(all_records[:5]):  \n",
    "    print(f\"Record {i+1}:\")\n",
    "    print(f\"  ID    : {record['id']}\")\n",
    "    print(f\"  Image : {record['img']}\")  \n",
    "    print(f\"  Label : {record['label'][:5]}...\")  \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28809ffc",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to out.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outv1.pickle\", \"wb\") as f:\n",
    "    pickle.dump(all_records, f)\n",
    "\n",
    "print(\"Data saved to out.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "312fadcb",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 13000 records from out.pickle\n"
     ]
    }
   ],
   "source": [
    "with open(\"outv1.pickle\", \"rb\") as f:\n",
    "    loaded_records = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(loaded_records)} records from out.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d0ea8",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original records: 13000\n",
      "Augmented records: 52000 (4x per original)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define augmentation pipeline (no resize)\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3)\n",
    "    ], p=0.3),\n",
    "])\n",
    "\n",
    "# Augment records\n",
    "augmented_records = []\n",
    "\n",
    "for record in loaded_records:\n",
    "    for _ in range(4):\n",
    "        img = record[\"img\"]\n",
    "        if not isinstance(img, Image.Image):\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "        # Apply augmentation\n",
    "        aug_img = augmentation(img)\n",
    "\n",
    "        # Create new record\n",
    "        new_record = {\n",
    "            \"id\": record[\"id\"],\n",
    "            \"img\": aug_img,\n",
    "            \"label\": record[\"label\"]\n",
    "        }\n",
    "        augmented_records.append(new_record)\n",
    "\n",
    "print(f\"Original records: {len(loaded_records)}\")\n",
    "print(f\"Augmented records: {len(augmented_records)} (4x per original)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07373e19",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data saved to augmented_out.pickle\n"
     ]
    }
   ],
   "source": [
    "with open(\"augmented_outv1.pickle\", \"wb\") as f:\n",
    "    pickle.dump(augmented_records, f)\n",
    "\n",
    "print(\"Augmented data saved to augmented_out.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460d8930",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 52000 augmented records.\n"
     ]
    }
   ],
   "source": [
    "# Load the augmented data\n",
    "with open(\"augmented_outv1.pickle\", \"rb\") as f:\n",
    "    augmented_records = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(augmented_records)} augmented records.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75608566",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade4a665",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd56b3e",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef3cc1",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/813 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========= 1. Load augmented data =========\n",
    "with open(\"/content/augmented_outv1.pickle\", \"rb\") as f:\n",
    "    augmented_records = pickle.load(f)\n",
    "\n",
    "# ========= 2. Keep only TWO samples per unique ID =========\n",
    "records_by_id = defaultdict(list)\n",
    "for rec in augmented_records:\n",
    "    records_by_id[rec[\"id\"]].append(rec)      \n",
    "\n",
    "filtered_records = []\n",
    "for lst in records_by_id.values():\n",
    "    random.shuffle(lst)\n",
    "    filtered_records.extend(lst[:2])          \n",
    "\n",
    "# 80/20 random split\n",
    "# ------------------------------------------------------------------------------\n",
    "dataset_size = len(filtered_records)\n",
    "train_len = int(0.8 * dataset_size)\n",
    "test_len  = dataset_size - train_len\n",
    "# ------------------------------------------------------------------------------\n",
    "# Create Dataset class first and then:\n",
    "# full_dataset = StolenDataset(filtered_records, transform)\n",
    "# train_dataset, test_dataset = random_split(full_dataset, [train_len, test_len])\n",
    "\n",
    "\n",
    "train_records, test_records = [], []\n",
    "for lst in records_by_id.values():\n",
    "    random.shuffle(lst)                       # shuffle again to avoid bias\n",
    "    train_records.append(lst[0])              # one for training\n",
    "    test_records.append(lst[1])               # one for testing\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# ========= 3. Dataset class =========\n",
    "class StolenDataset(Dataset):\n",
    "    def __init__(self, records, transform=None):\n",
    "        self.records = records\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.records[idx]\n",
    "        img = rec[\"img\"]                      \n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        label = torch.tensor(rec[\"label\"], dtype=torch.float32)\n",
    "        return self.transform(img) if self.transform else img, label\n",
    "\n",
    "# ========= 4. Transform & DataLoaders =========\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.2980, 0.2962, 0.2987],\n",
    "                         std=[0.2886, 0.2875, 0.2889]),\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    StolenDataset(train_records, transform),  \n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    StolenDataset(test_records, transform),   \n",
    "    batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "\n",
    "# ========= 5. Model, device, loss, optimiser =========\n",
    "model = models.resnet18(weights=None)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(model.fc.in_features, 1024)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ========= 6. Training loop =========\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(imgs), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    print(f\"Epoch {epoch+1}: avg train loss = {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# ========= 7. Quick test pass =========\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        test_loss += loss_fn(model(imgs), labels).item()\n",
    "print(f\"\\nTest loss (MSE): {test_loss / len(test_loader):.4f}\")\n",
    "\n",
    "# ========= 8. Save model =========\n",
    "torch.save(model.state_dict(), \"stolen_model.pth\")\n",
    "print(\"Model saved as stolen_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fba15",
   "metadata": {},
   "source": [
    "Saved model as stolen_model.pth had to change it to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396e17a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1.  Set up Python imports\n",
    "# -----------------------------------------------------------\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2.  Rebuild the model architecture exactly as before\n",
    "# -----------------------------------------------------------\n",
    "model = models.resnet18(weights=None)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(model.fc.in_features, 1024)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3.  Load your trained weights\n",
    "# -----------------------------------------------------------\n",
    "weights_path = \"stolen_model.pth\"            \n",
    "state_dict   = torch.load(weights_path, map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()                                          \n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4.  Export to ONNX with clear tensor names\n",
    "# -----------------------------------------------------------\n",
    "onnx_path = \"stolen_model.onnx\"        \n",
    "dummy     = torch.randn(1, 3, 32, 32)                 \n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy,\n",
    "    onnx_path,\n",
    "    opset_version=12,            \n",
    "    input_names=[\"x\"],           \n",
    "    output_names=[\"features\"],   \n",
    "    dynamic_axes={\n",
    "        \"x\":        {0: \"batch\"},    \n",
    "        \"features\": {0: \"batch\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"ONNX model saved to {onnx_path}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5.  Sanity-check with onnxruntime \n",
    "# -----------------------------------------------------------\n",
    "sess = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
    "print(\"Input  name:\", sess.get_inputs()[0].name)      \n",
    "print(\"Output name:\", sess.get_outputs()[0].name)     \n",
    "\n",
    "test_out = sess.run(\n",
    "    None, {\"x\": np.random.randn(1, 3, 32, 32).astype(np.float32)}\n",
    ")[0][0]\n",
    "\n",
    "assert test_out.shape == (1024,), f\"Unexpected output shape: {test_out.shape}\"\n",
    "print(\"Dry-run successful — output shape:\", test_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06afe03",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  : x\n",
      "Output : features\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "path = \"stolen_model.onnx\"\n",
    "sess = ort.InferenceSession(path)\n",
    "\n",
    "# Discover what the model actually expects\n",
    "input_name  = sess.get_inputs()[0].name      \n",
    "output_name = sess.get_outputs()[0].name     \n",
    "print(\"Input  :\", input_name)\n",
    "print(\"Output :\", output_name)\n",
    "\n",
    "# Create a dummy batch and run\n",
    "dummy = np.random.randn(1, 3, 32, 32).astype(np.float32)\n",
    "out   = sess.run(None, {input_name: dummy})[0][0]  # drop batch dim\n",
    "assert out.shape == (1024,), \"Unexpected output shape\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7011acdb",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='34.122.51.94', port=9090): Max retries exceeded with url: /stealing (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001DF6F8DCD10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\connection.py:445\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\http\\client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\http\\client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\http\\client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\connection.py:276\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    278\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\connection.py:213\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    214\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    217\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPConnection object at 0x000001DF6F8DCD10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPConnectionPool(host='34.122.51.94', port=9090): Max retries exceeded with url: /stealing (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001DF6F8DCD10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m out.shape == (\u001b[32m1024\u001b[39m,), \u001b[33m\"\u001b[39m\u001b[33mInvalid output shape\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Send the model to the server\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttp://34.122.51.94:9090/stealing\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtoken\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOKEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hassa\\anaconda3\\envs\\tml_a2\\Lib\\site-packages\\requests\\adapters.py:700\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    696\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    697\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m    698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    703\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPConnectionPool(host='34.122.51.94', port=9090): Max retries exceeded with url: /stealing (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001DF6F8DCD10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "SEED = str(36604352) \n",
    "PORT = str(9340) \n",
    "TOKEN = \"61729223\" \n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    model = f.read()\n",
    "    try:\n",
    "        stolen_model = ort.InferenceSession(model)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid model, {e=}\")\n",
    "    try:\n",
    "        out = stolen_model.run(\n",
    "            None, {\"x\": np.random.randn(1, 3, 32, 32).astype(np.float32)}\n",
    "        )[0][0]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Some issue with the input, {e=}\")\n",
    "    assert out.shape == (1024,), \"Invalid output shape\"\n",
    "\n",
    "# Send the model to the server\n",
    "response = requests.post(\"http://34.122.51.94:9090/stealing\", files={\"file\": open(path, \"rb\")}, headers={\"token\": TOKEN, \"seed\": SEED})\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tml_a2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
