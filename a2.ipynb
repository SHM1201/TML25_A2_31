{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0594a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests onnx onnxruntime transformers datasets accelerate sentencepiece matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de6c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa83919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import sys\n",
    "import base64\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf14ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 36604352, 'port': '9340'}\n"
     ]
    }
   ],
   "source": [
    "### REQUESTING NEW API ### \n",
    "TOKEN = \"61729223\" \n",
    " \n",
    "response = requests.get(\"http://34.122.51.94:9090\" + \"/stealing_launch\", \n",
    "headers={\"token\": TOKEN}) \n",
    "answer = response.json() \n",
    " \n",
    "print(answer) \n",
    "if 'detail' in answer: \n",
    "    sys.exit(1) \n",
    " \n",
    "# save the values \n",
    "SEED = str(answer['seed']) \n",
    "PORT = str(answer['port']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f74078",
   "metadata": {},
   "source": [
    "{'seed': 36604352, 'port': '9340'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad5f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if not self.transform is None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e09f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.2980, 0.2962, 0.2987]\n",
    "std = [0.2886, 0.2875, 0.2889]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "dataset: TaskDataset = torch.load(\"ModelStealingPub.pt\", weights_only=False)\n",
    "dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b17d5f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from typing import List, Dict\n",
    "\n",
    "def model_stealing(ids: List[int], imgs: List, port: int) -> List[Dict]:\n",
    "    endpoint = \"/query\"\n",
    "    url = f\"http://34.122.51.94:{port}{endpoint}\"\n",
    "    \n",
    "    image_data = []\n",
    "    for img in imgs:\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        image_data.append(img_base64)\n",
    "\n",
    "    payload = json.dumps(image_data)\n",
    "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": TOKEN})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        representations = response.json()[\"representations\"]\n",
    "        output = [\n",
    "            {\"id\": id_, \"img\": img, \"label\": rep}\n",
    "            for id_, img, rep in zip(ids, imgs, representations)\n",
    "        ]\n",
    "        return output\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Model stealing failed. Code: {response.status_code}, content: {response.json()}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825a476",
   "metadata": {},
   "source": [
    "Querying data from the vitcim model in batch of 1000s with time delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "700f1c3c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 2 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 3 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 4 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 5 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 6 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 7 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 8 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 9 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 10 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 11 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 12 processed successfully.\n",
      "Waiting 90 seconds to respect API rate limit...\n",
      "Batch 13 processed successfully.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 1000\n",
    "all_records = []\n",
    "\n",
    "# Shuffle and batch\n",
    "indices = np.random.permutation(len(dataset))\n",
    "\n",
    "for start in range(0, len(indices), batch_size):\n",
    "    end = start + batch_size\n",
    "    batch_indices = indices[start:end]\n",
    "\n",
    "    batch_ids = [dataset.ids[i] for i in batch_indices]\n",
    "    batch_imgs = [dataset.imgs[i] for i in batch_indices]\n",
    "\n",
    "    try:\n",
    "        batch_output = model_stealing(batch_ids, batch_imgs, port=PORT)\n",
    "        all_records.extend(batch_output)\n",
    "        print(f\"Batch {start // batch_size + 1} processed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error on batch {start // batch_size + 1}: {e}\")\n",
    "    \n",
    "    # Wait 90 seconds (1.5 minutes) between requests\n",
    "    if end < len(indices):  # Avoid waiting after last batch\n",
    "        print(\"Waiting 90 seconds to respect API rate limit...\")\n",
    "        time.sleep(90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0561a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\nTotal records collected: {len(all_records)}\\n\")\n",
    "\n",
    "# Print few samples\n",
    "for i, record in enumerate(all_records[:5]):  \n",
    "    print(f\"Record {i+1}:\")\n",
    "    print(f\"  ID    : {record['id']}\")\n",
    "    print(f\"  Image : {record['img']}\")  \n",
    "    print(f\"  Label : {record['label'][:5]}...\")  \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28809ffc",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to out.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outv1.pickle\", \"wb\") as f:\n",
    "    pickle.dump(all_records, f)\n",
    "\n",
    "print(\"Data saved to out.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "312fadcb",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 13000 records from out.pickle\n"
     ]
    }
   ],
   "source": [
    "with open(\"outv1.pickle\", \"rb\") as f:\n",
    "    loaded_records = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(loaded_records)} records from out.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d0ea8",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original records: 13000\n",
      "Augmented records: 52000 (4x per original)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define augmentation pipeline (no resize)\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3)\n",
    "    ], p=0.3),\n",
    "])\n",
    "\n",
    "# Augment records\n",
    "augmented_records = []\n",
    "\n",
    "for record in loaded_records:\n",
    "    for _ in range(4):\n",
    "        img = record[\"img\"]\n",
    "        if not isinstance(img, Image.Image):\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "        # Apply augmentation\n",
    "        aug_img = augmentation(img)\n",
    "\n",
    "        # Create new record\n",
    "        new_record = {\n",
    "            \"id\": record[\"id\"],\n",
    "            \"img\": aug_img,\n",
    "            \"label\": record[\"label\"]\n",
    "        }\n",
    "        augmented_records.append(new_record)\n",
    "\n",
    "print(f\"Original records: {len(loaded_records)}\")\n",
    "print(f\"Augmented records: {len(augmented_records)} (4x per original)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07373e19",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data saved to augmented_out.pickle\n"
     ]
    }
   ],
   "source": [
    "with open(\"augmented_outv1.pickle\", \"wb\") as f:\n",
    "    pickle.dump(augmented_records, f)\n",
    "\n",
    "print(\"Augmented data saved to augmented_out.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460d8930",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 52000 augmented records.\n"
     ]
    }
   ],
   "source": [
    "# Load the augmented data\n",
    "with open(\"augmented_outv1.pickle\", \"rb\") as f:\n",
    "    augmented_records = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(augmented_records)} augmented records.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75608566",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade4a665",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd56b3e",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef3cc1",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========= 1. Load augmented data =========\n",
    "with open(\"/content/augmented_outv1.pickle\", \"rb\") as f:\n",
    "    augmented_records = pickle.load(f)\n",
    "\n",
    "# ========= 2. Keep only TWO samples per unique ID =========\n",
    "records_by_id = defaultdict(list)\n",
    "for rec in augmented_records:\n",
    "    records_by_id[rec[\"id\"]].append(rec)      \n",
    "\n",
    "filtered_records = []\n",
    "for lst in records_by_id.values():\n",
    "    random.shuffle(lst)\n",
    "    filtered_records.extend(lst[:2])          \n",
    "\n",
    "# 80/20 random split\n",
    "# ------------------------------------------------------------------------------\n",
    "dataset_size = len(filtered_records)\n",
    "train_len = int(0.8 * dataset_size)\n",
    "test_len  = dataset_size - train_len\n",
    "# ------------------------------------------------------------------------------\n",
    "# Create Dataset class first and then:\n",
    "# full_dataset = StolenDataset(filtered_records, transform)\n",
    "# train_dataset, test_dataset = random_split(full_dataset, [train_len, test_len])\n",
    "\n",
    "\n",
    "train_records, test_records = [], []\n",
    "for lst in records_by_id.values():\n",
    "    random.shuffle(lst)                       # shuffle again to avoid bias\n",
    "    train_records.append(lst[0])              # one for training\n",
    "    test_records.append(lst[1])               # one for testing\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# ========= 3. Dataset class =========\n",
    "class StolenDataset(Dataset):\n",
    "    def __init__(self, records, transform=None):\n",
    "        self.records = records\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.records[idx]\n",
    "        img = rec[\"img\"]                      \n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        label = torch.tensor(rec[\"label\"], dtype=torch.float32)\n",
    "        return self.transform(img) if self.transform else img, label\n",
    "\n",
    "# ========= 4. Transform & DataLoaders =========\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.2980, 0.2962, 0.2987],\n",
    "                         std=[0.2886, 0.2875, 0.2889]),\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    StolenDataset(train_records, transform),  \n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    StolenDataset(test_records, transform),   \n",
    "    batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "\n",
    "# ========= 5. Model, device, loss, optimiser =========\n",
    "model = models.resnet18(weights=None)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(model.fc.in_features, 1024)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ========= 6. Training loop =========\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(imgs), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    print(f\"Epoch {epoch+1}: avg train loss = {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# ========= 7. Quick test pass =========\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        test_loss += loss_fn(model(imgs), labels).item()\n",
    "print(f\"\\nTest loss (MSE): {test_loss / len(test_loader):.4f}\")\n",
    "\n",
    "# ========= 8. Save model =========\n",
    "torch.save(model.state_dict(), \"stolen_model.pth\")\n",
    "print(\"Model saved as stolen_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fba15",
   "metadata": {},
   "source": [
    "Saved model as stolen_model.pth had to change it to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396e17a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1.  Set up Python imports\n",
    "# -----------------------------------------------------------\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2.  Rebuild the model architecture exactly as before\n",
    "# -----------------------------------------------------------\n",
    "model = models.resnet18(weights=None)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(model.fc.in_features, 1024)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3.  Load your trained weights\n",
    "# -----------------------------------------------------------\n",
    "weights_path = \"stolen_model.pth\"            \n",
    "state_dict   = torch.load(weights_path, map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()                                          \n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4.  Export to ONNX with clear tensor names\n",
    "# -----------------------------------------------------------\n",
    "onnx_path = \"stolen_model.onnx\"        \n",
    "dummy     = torch.randn(1, 3, 32, 32)                 \n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy,\n",
    "    onnx_path,\n",
    "    opset_version=12,            \n",
    "    input_names=[\"x\"],           \n",
    "    output_names=[\"features\"],   \n",
    "    dynamic_axes={\n",
    "        \"x\":        {0: \"batch\"},    \n",
    "        \"features\": {0: \"batch\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"ONNX model saved to {onnx_path}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5.  Sanity-check with onnxruntime \n",
    "# -----------------------------------------------------------\n",
    "sess = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
    "print(\"Input  name:\", sess.get_inputs()[0].name)      \n",
    "print(\"Output name:\", sess.get_outputs()[0].name)     \n",
    "\n",
    "test_out = sess.run(\n",
    "    None, {\"x\": np.random.randn(1, 3, 32, 32).astype(np.float32)}\n",
    ")[0][0]\n",
    "\n",
    "assert test_out.shape == (1024,), f\"Unexpected output shape: {test_out.shape}\"\n",
    "print(\"Dry-run successful — output shape:\", test_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06afe03",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  : x\n",
      "Output : features\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "path = \"stolen_model.onnx\"\n",
    "sess = ort.InferenceSession(path)\n",
    "\n",
    "# Discover what the model actually expects\n",
    "input_name  = sess.get_inputs()[0].name      \n",
    "output_name = sess.get_outputs()[0].name     \n",
    "print(\"Input  :\", input_name)\n",
    "print(\"Output :\", output_name)\n",
    "\n",
    "# Create a dummy batch and run\n",
    "dummy = np.random.randn(1, 3, 32, 32).astype(np.float32)\n",
    "out   = sess.run(None, {input_name: dummy})[0][0]  # drop batch dim\n",
    "assert out.shape == (1024,), \"Unexpected output shape\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7011acdb",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "SEED = str(36604352) \n",
    "PORT = str(9340) \n",
    "TOKEN = \"61729223\" \n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    model = f.read()\n",
    "    try:\n",
    "        stolen_model = ort.InferenceSession(model)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid model, {e=}\")\n",
    "    try:\n",
    "        out = stolen_model.run(\n",
    "            None, {\"x\": np.random.randn(1, 3, 32, 32).astype(np.float32)}\n",
    "        )[0][0]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Some issue with the input, {e=}\")\n",
    "    assert out.shape == (1024,), \"Invalid output shape\"\n",
    "\n",
    "# Send the model to the server\n",
    "response = requests.post(\"http://34.122.51.94:9090/stealing\", files={\"file\": open(path, \"rb\")}, headers={\"token\": TOKEN, \"seed\": SEED})\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tml_a2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
